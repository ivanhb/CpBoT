{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'location', 'date', 'contribution', 'description', 'extra']\n",
      "About: WikiCite 2018 is a 3-day conference, summit, and hack day dedicated to the vision of creating an open repository of bibliographic data to support the citation and fact-checking needs of Wikimedia projects, and possibly, to serve as an open infrastructure for research, education, and information quality across the web.\n",
      "Conference website: https://meta.wikimedia.org/wiki/WikiCite_2018\n",
      "View the presentation: https://docs.google.com/presentation/d/1lM8HDFUytUEQ2vu603yJ0R1T8qTdsx8q50o5vP9y2so/edit?usp=sharing\n",
      "Lucinda demo for Wikidata: https://opencitations.github.io/lucinda/example/wikidata/browser.html?browse=Q30536251\n",
      "OSCAR demo for Wikidata: https://opencitations.github.io/oscar/example/v2/wikidata.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import urllib.request\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "\n",
    "\n",
    "str_to_return = \"\"\n",
    "api_call = \"https://ivanhb.github.io/data/activity.csv\"\n",
    "\n",
    "contents = urllib.request.urlopen(api_call).read().decode('utf-8')\n",
    "arr_rows = str(contents).split('\\n')\n",
    "csv_matrix = list(csv.reader(arr_rows))\n",
    "\n",
    "print(csv_file[0])\n",
    "str_to_send = \"\"\n",
    "str_to_send= \"Event: \"+csv_file[1][0] + \"\\n\"\n",
    "str_to_send= \"At : \"+csv_file[1][1] + \"\\n\"\n",
    "str_to_send= \"On : \"+csv_file[1][2] + \"\\n\"\n",
    "str_to_send= \"My contribution: \"+csv_file[1][3] + \"\\n\"\n",
    "str_to_send= \"About: \"+csv_file[1][4] + \"\\n\"\n",
    "\n",
    "arr_ext = csv_file[1][5].split(']],[[')\n",
    "str_all_ext = \"\"\n",
    "for ex_i in arr_ext:\n",
    "    ex_i = ex_i.replace('[[','')\n",
    "    ex_i = ex_i.replace(']]','')\n",
    "    ex_parts_i = ex_i.split(',')\n",
    "\n",
    "    if ex_parts_i[0][:4] == 'link':\n",
    "        str_all_ext = str_all_ext + ex_parts_i[1]+ \": \" + ex_parts_i[2] + '\\n'\n",
    "\n",
    "str_to_send = str_to_send + str_all_ext\n",
    "print(str_to_send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_my_commands' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-24468f828b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#module_name = getattr(sys.modules[__name__] ,'bot_avatar.py')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_my_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_my_commands' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from modules import *  \n",
    "#module_name = getattr(sys.modules[__name__] ,'bot_avatar.py')\n",
    "\n",
    "msg = get_my_commands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import glob\n",
    "import importlib.util\n",
    "import re\n",
    "\n",
    "spec = importlib.util.spec_from_file_location('bot_avatar','modules/bot_avatar.py')\n",
    "foo = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(foo)\n",
    "\n",
    "print(foo.exec_my_commands('last_activity','ciao'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Heibi I., Peroni S., Shotton D. (2018) OSCAR: A Customisable Tool for Free-Text Search over SPARQL Endpoints. In: Gonz치lez-Beltr치n A., Osborne F., Peroni S., Vahdati S. (eds) Semantics, Analytics, Visualization. SAVE-SD 2017, SAVE-SD 2018. Lecture Notes in Computer Science, vol 10959. Springer, Cham', '2018', '[[link_text,https://doi.org/10.1007/978-3-030-01379-0_9,https://doi.org/10.1007/978-3-030-01379-0_9]]']\n",
      "['Upcoming: Heibi I., Peroni S., Shotton D. Enabling text search on SPARQL-endpoints through OSCAR. Data Science.', '', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nHeibi I., Peroni S., Shotton D. (2018) OSCAR: A Customisable Tool for Free-Text Search over SPARQL Endpoints. In: Gonz치lez-Beltr치n A., Osborne F., Peroni S., Vahdati S. (eds) Semantics, Analytics, Visualization. SAVE-SD 2017, SAVE-SD 2018. Lecture Notes in Computer Science, vol 10959. Springer, Cham\\nhttps://doi.org/10.1007/978-3-030-01379-0_9: https://doi.org/10.1007/978-3-030-01379-0_9\\n\\n\\n\\nUpcoming: Heibi I., Peroni S., Shotton D. Enabling text search on SPARQL-endpoints through OSCAR. Data Science.\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import glob\n",
    "import importlib.util\n",
    "import re\n",
    "import urllib.request\n",
    "import csv\n",
    "\n",
    "def list_publications(a_text):\n",
    "    str_to_return = \"\"\n",
    "    api_call = \"https://ivanhb.github.io/data/publication.csv\"\n",
    "    csv_matrix = get_csv_file(api_call)\n",
    "    \n",
    "    str_to_send = \"\"\n",
    "    if csv_matrix != [] and csv_matrix != -1:\n",
    "        for i in range(1,len(csv_matrix)):\n",
    "            str_to_send = str_to_send + \"\\n\"+csv_matrix[i][0]\n",
    "            if csv_matrix[i][2] != \"\":\n",
    "                str_to_send = str_to_send + \"\\n\" + handle_extra_elem(csv_matrix[i][2])\n",
    "            str_to_send = str_to_send + \" \\n\\n\"\n",
    "\n",
    "    return str_to_send\n",
    "\n",
    "def get_csv_file(api_call):\n",
    "\n",
    "    contents = urllib.request.urlopen(api_call).read().decode('utf-8')\n",
    "    #print(urllib.request.urlopen(\"https://ivanhb.github.io/data/publication.csv\").read().decode('utf-8'))\n",
    "    arr_rows = str(contents).split('\\n')\n",
    "    #print(arr_rows)\n",
    "    return list(csv.reader(arr_rows))\n",
    "\n",
    "\n",
    "def handle_extra_elem(ext_elem):\n",
    "    arr_ext = ext_elem.split(']],[[')\n",
    "    str_all_ext = \"\"\n",
    "    for ex_i in arr_ext:\n",
    "        ex_i = ex_i.replace('[[','')\n",
    "        ex_i = ex_i.replace(']]','')\n",
    "        ex_parts_i = ex_i.split(',')\n",
    "\n",
    "        if ex_parts_i[0][:4] == 'link':\n",
    "            str_all_ext = str_all_ext + ex_parts_i[1]+ \": \" + ex_parts_i[2] + '\\n'\n",
    "    return str_all_ext\n",
    "\n",
    "list_publications(\"ll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
